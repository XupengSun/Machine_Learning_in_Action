# 问题描述

A类点以（0，0）为中心、（1，0；0，1）为协方差矩阵的二维高斯分布；

B类点以（1，2）为中心、（1，0；0，2）为协方差矩阵的二维高斯分布；

随机生成300个A类点，200个B类点，并用Logistic回归方法进行分类(GD,SGD)画出不同epoch等参数下的结果

# 具体过程与算法原理

## 数据生成

根据要求用numpy生成500个点，将位置坐标放入dataSet数组中,前三百个为A类点,后三百个为B类点。再生成一个label数组，包含300个1(用来表示A类)和200个2(用来表示B类).

画图展示生成的效果:

![image-20210130092043983](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092043983.png)

## 定义Sigmoid函数

下图展示了单位阶跃函数（红色）与对数几率函数（黑色）：

![image-20210130092104407](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092104407.png)

从上图可以看出，单位阶跃函数不连续，数学性质差，因此不能直接用作广义线性模型中的link function，于是我们的目的是找到在一定程度上近似单位阶跃函数的"替代函数"（surrogate function），并希望它单调可微。对数几率函数（logistic function）正是这样一个常用的替代函数：

![image-20210130092114971](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092114971.png)

对数几率函数是一种"Sigmoid"函数（即形似S的函数，在神经网络的激励函数中有广泛应用），它将z值转化为一个接近0或1的y值，并且其输出值在z=0附近变化很陡。将该对数几率函数作为联系函数代入广义线性模型，可得：

![image-20210130092122149](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092122149.png)

(以上部分来自《机器学习》)

##  模型设计

### 初始化与前向计算

这里假定将输入特征和输出预测值均以向量表示，输入特征x有2个分量，label y有1个分量，那么参数权重的形状是2x1 .同时完整的回归公式，还需要初始化偏移量bias。因此在初始化时随机生成权重$w$与偏置量$b$.

在forward方法中进行参数的前向计算,首先生成线性回归方程,然后将线性回归方程代入sigmoid函数中获得预测函数:

![image-20210130092203470](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092203470.png)

###  损失函数

在进行完前向计算后,我们得到预测值z,这时我们需要有某种指标来衡量预测值z跟真实值y之间的差距。对于回归问题，最常采用的衡量方法是使用均方误差作为评价模型好坏的指标，具体定义如下：

![image-20210130092221397](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092221397.png)

上式中的Loss通常也被称作损失函数，它是衡量模型好坏的指标。该问题中我们使用均方误差作为损失函数,均方误差是一种比较常见的损失函数,其表达式实现如下：

![image-20210130092228090](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092228090.png)

### 求梯度与更新梯度

根据梯度的定义可以计算出L对w和b的偏导数：

![image-20210130092244557](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092244557.png)

计算出梯度后对w和b进行更新,其中eta为每次更新的步长.

### 模型训练

在每个周期内一次进行前向计算,损失函数计算,梯度更新.通过不断地迭代使得梯度更新的方程权重达到令损失函数最小的目的.

## 结果分析

### 不同epoch数值下逻辑回归的正确率

通过在1,1000范围内每五十个点取一次epoch数值进行迭代训练.

![image-20210130092314818](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092314818.png)

可以观察到随着epoch的增加,训练后的正确率也逐渐上升,基本符合预期.

### 最佳拟合决策分界线

![image-20210130092326720](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092326720.png)

通过统计上述epoch下的正确率,可以寻得最佳epoch下的输出参数,然后根据该输出参数可以绘制logistics回归的二分类曲线,如上图所示.

## SGD(随机梯度下降分析)

上述程序和效果图均是给予整体的梯度下降,本小节是有关随机梯度下降的有关实现程序.有关SGD的代码同GD大致相同,仅需在有关计算梯度的部分进行修改即可.

在进行随机梯度下降的有关计算时,先将数据的排列顺序打乱,然后将数据分成很小的mini\_batches每次仅计算一个mini\_batch的梯度作为整个整体的梯度进行更新,这样做对于大数据量的模型计算具有很强的优势,本题数据量较小,故而效果不是很明显.

### 不同epoch数值下逻辑回归的正确率

![image-20210130092350952](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092350952.png)

这里显示在相同epoch的条件下,SGD相比于GD能更快到达较高的正确率的原因是,在编写代码的过程中SGD设计为每个epoch内都会将所有的mini\_batch计算一遍梯度,而在GD中仅有一个batch仅计算一次,因此相当于SGD实际的迭代次数是大于GD的.要更显著的比较SGD同GD的不同,可见下面的分析.

### 最佳拟合决策分界线

![image-20210130092404447](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092404447.png)

## GD与SGD的对比

如下图所示,图一为GD算法时最优epoch训练时loss的变化趋势.图二为SGD算法时最优epoch训练的loss变化趋势.

可以观察到GD算法,loss的变化是平缓下降的,因为GD每次计算的是所有点的梯度平均值,因此总能使得整体的损失是减少的.而SGD的变化趋势是震荡下降的,因为每次计算的梯度是一个mini\_batch的梯度,而这个梯度对于总体的数据来说可能是起反向作用的,因此是震荡式下降的.

![image-20210130092417097](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092417097.png)

![image-20210130092427715](https://gitee.com/sun-roc/picture/raw/master/img/image-20210130092427715.png)
